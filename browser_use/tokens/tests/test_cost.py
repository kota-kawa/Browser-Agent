# EN: Describe this block with a docstring.
# JP: ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã®èª¬æ˜ã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ–‡å­—åˆ—ã§è¨˜è¿°ã™ã‚‹ã€‚
"""
Simple test for token cost tracking with real LLM calls.

Tests ChatOpenAI and ChatGoogle by iteratively generating countries.
"""

# EN: Import required modules.
# JP: å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã€‚
import asyncio
# EN: Import required modules.
# JP: å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã€‚
import logging

# EN: Import required modules.
# JP: å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã€‚
from browser_use.llm import ChatOpenAI
# EN: Import required modules.
# JP: å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã€‚
from browser_use.llm.messages import AssistantMessage, SystemMessage, UserMessage
# EN: Import required modules.
# JP: å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã€‚
from browser_use.tokens.service import TokenCost

# EN: Assign value to logger.
# JP: logger ã«å€¤ã‚’ä»£å…¥ã™ã‚‹ã€‚
logger = logging.getLogger(__name__)
# EN: Evaluate an expression.
# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
logger.setLevel(logging.INFO)


# EN: Define async function `test_iterative_country_generation`.
# JP: éåŒæœŸé–¢æ•° `test_iterative_country_generation` ã‚’å®šç¾©ã™ã‚‹ã€‚
async def test_iterative_country_generation():
	# EN: Describe this block with a docstring.
	# JP: ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã®èª¬æ˜ã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ–‡å­—åˆ—ã§è¨˜è¿°ã™ã‚‹ã€‚
	"""Test token cost tracking with iterative country generation"""

	# Initialize token cost service
	# EN: Assign value to tc.
	# JP: tc ã«å€¤ã‚’ä»£å…¥ã™ã‚‹ã€‚
	tc = TokenCost(include_cost=True)

	# System prompt that explains the iterative task
	# EN: Assign value to system_prompt.
	# JP: system_prompt ã«å€¤ã‚’ä»£å…¥ã™ã‚‹ã€‚
	system_prompt = """You are a country name generator. When asked, you will provide exactly ONE country name and nothing else.
Each time you're asked to continue, provide the next country name that hasn't been mentioned yet.
Keep track of which countries you've already said and don't repeat them.
Only output the country name, no numbers, no punctuation, just the name."""

	# Test with different models
	# EN: Assign value to models.
	# JP: models ã«å€¤ã‚’ä»£å…¥ã™ã‚‹ã€‚
	models = [
		ChatOpenAI(model='gpt-4.1'),
		# ChatGoogle(model='gemini-2.0-flash-exp'),
	]

	# EN: Evaluate an expression.
	# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
	print('\nğŸŒ Iterative Country Generation Test')
	# EN: Evaluate an expression.
	# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
	print('=' * 80)

	# EN: Iterate over items in a loop.
	# JP: ãƒ«ãƒ¼ãƒ—ã§è¦ç´ ã‚’é †ã«å‡¦ç†ã™ã‚‹ã€‚
	for llm in models:
		# EN: Evaluate an expression.
		# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
		print(f'\nğŸ“ Testing {llm.model}')
		# EN: Evaluate an expression.
		# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
		print('-' * 60)

		# Register the LLM for automatic tracking
		# EN: Evaluate an expression.
		# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
		tc.register_llm(llm)

		# Initialize conversation
		# EN: Assign value to messages.
		# JP: messages ã«å€¤ã‚’ä»£å…¥ã™ã‚‹ã€‚
		messages = [SystemMessage(content=system_prompt), UserMessage(content='Give me a country name')]

		# EN: Assign value to countries.
		# JP: countries ã«å€¤ã‚’ä»£å…¥ã™ã‚‹ã€‚
		countries = []

		# Generate 10 countries iteratively
		# EN: Iterate over items in a loop.
		# JP: ãƒ«ãƒ¼ãƒ—ã§è¦ç´ ã‚’é †ã«å‡¦ç†ã™ã‚‹ã€‚
		for i in range(10):
			# Call the LLM
			# EN: Assign value to result.
			# JP: result ã«å€¤ã‚’ä»£å…¥ã™ã‚‹ã€‚
			result = await llm.ainvoke(messages)
			# EN: Assign value to country.
			# JP: country ã«å€¤ã‚’ä»£å…¥ã™ã‚‹ã€‚
			country = result.completion.strip()
			# EN: Evaluate an expression.
			# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
			countries.append(country)

			# Add the response to messages
			# EN: Evaluate an expression.
			# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
			messages.append(AssistantMessage(content=country))

			# Add the next request (except for the last iteration)
			# EN: Branch logic based on a condition.
			# JP: æ¡ä»¶ã«å¿œã˜ã¦å‡¦ç†ã‚’åˆ†å²ã™ã‚‹ã€‚
			if i < 9:
				# EN: Evaluate an expression.
				# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
				messages.append(UserMessage(content='Next country please'))

			# EN: Evaluate an expression.
			# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
			print(f'  Country {i + 1}: {country}')

		# EN: Evaluate an expression.
		# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
		print(f'\n  Generated countries: {", ".join(countries)}')

	# Display cost summary
	# EN: Evaluate an expression.
	# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
	print('\nğŸ’° Cost Summary')
	# EN: Evaluate an expression.
	# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
	print('=' * 80)

	# EN: Assign value to summary.
	# JP: summary ã«å€¤ã‚’ä»£å…¥ã™ã‚‹ã€‚
	summary = await tc.get_usage_summary()
	# EN: Evaluate an expression.
	# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
	print(f'Total calls: {summary.entry_count}')
	# EN: Evaluate an expression.
	# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
	print(f'Total tokens: {summary.total_tokens:,}')
	# EN: Evaluate an expression.
	# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
	print(f'Total cost: ${summary.total_cost:.6f}')

	# EN: Assign value to expected_cost.
	# JP: expected_cost ã«å€¤ã‚’ä»£å…¥ã™ã‚‹ã€‚
	expected_cost = 0
	# EN: Assign value to expected_invocations.
	# JP: expected_invocations ã«å€¤ã‚’ä»£å…¥ã™ã‚‹ã€‚
	expected_invocations = 0

	# EN: Evaluate an expression.
	# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
	print('\nğŸ“Š Cost breakdown by model:')
	# EN: Iterate over items in a loop.
	# JP: ãƒ«ãƒ¼ãƒ—ã§è¦ç´ ã‚’é †ã«å‡¦ç†ã™ã‚‹ã€‚
	for model, stats in summary.by_model.items():
		# EN: Update variable with augmented assignment.
		# JP: è¤‡åˆä»£å…¥ã§å¤‰æ•°ã‚’æ›´æ–°ã™ã‚‹ã€‚
		expected_cost += stats.cost
		# EN: Update variable with augmented assignment.
		# JP: è¤‡åˆä»£å…¥ã§å¤‰æ•°ã‚’æ›´æ–°ã™ã‚‹ã€‚
		expected_invocations += stats.invocations

		# EN: Evaluate an expression.
		# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
		print(f'\n{model}:')
		# EN: Evaluate an expression.
		# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
		print(f'  Calls: {stats.invocations}')
		# EN: Evaluate an expression.
		# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
		print(f'  Prompt tokens: {stats.prompt_tokens:,}')
		# EN: Evaluate an expression.
		# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
		print(f'  Completion tokens: {stats.completion_tokens:,}')
		# EN: Evaluate an expression.
		# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
		print(f'  Total tokens: {stats.total_tokens:,}')
		# EN: Evaluate an expression.
		# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
		print(f'  Cost: ${stats.cost:.6f}')
		# EN: Evaluate an expression.
		# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
		print(f'  Average tokens per call: {stats.average_tokens_per_invocation:.1f}')

	# EN: Validate a required condition.
	# JP: å¿…é ˆæ¡ä»¶ã‚’æ¤œè¨¼ã™ã‚‹ã€‚
	assert summary.entry_count == expected_invocations, f'Expected {expected_invocations} invocations, got {summary.entry_count}'
	# EN: Validate a required condition.
	# JP: å¿…é ˆæ¡ä»¶ã‚’æ¤œè¨¼ã™ã‚‹ã€‚
	assert abs(summary.total_cost - expected_cost) < 1e-6, (
		f'Expected total cost ${expected_cost:.6f}, got ${summary.total_cost:.6f}'
	)


# EN: Branch logic based on a condition.
# JP: æ¡ä»¶ã«å¿œã˜ã¦å‡¦ç†ã‚’åˆ†å²ã™ã‚‹ã€‚
if __name__ == '__main__':
	# Run the test
	# EN: Evaluate an expression.
	# JP: å¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚
	asyncio.run(test_iterative_country_generation())
